// ë¡œì»¬ ê°œë°œ í™˜ê²½ ê°ì§€
const isOffline = process.env.IS_OFFLINE || process.env.NODE_ENV === 'development';

/**
 * ìŠ¤íŠœë””ì˜¤ ì •ë³´ ìŠ¤í¬ëž˜í•‘ Lambda í•¸ë“¤ëŸ¬
 */
module.exports.scrape = async (event) => {
  console.log('Studio scraping handler called');

  // ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ìŠ¤í¬ëž˜í•‘ ìŠ¤í‚µ
  if (isOffline) {
    console.log('ðŸ”§ Running in offline mode - skipping scraping');
    return {
      statusCode: 200,
      body: JSON.stringify({
        message: 'ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” ìŠ¤í¬ëž˜í•‘ì„ ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.',
        isOffline: true,
        note: 'AWSì— ë°°í¬ í›„ ì‹¤ì œ ìŠ¤í¬ëž˜í•‘ì´ ì‹¤í–‰ë©ë‹ˆë‹¤.'
      })
    };
  }

  try {
    const StudioScraper = require('../scrapers/studioScraper');
    const { batchWrite } = require('../utils/dynamodb');
    const { SCRAPE_URLS } = require('../config/constants');

    console.log('Starting studio scraping...');
    const allStudios = [];

    // ëª¨ë“  URLì—ì„œ ìŠ¤í¬ëž˜í•‘
    for (const url of SCRAPE_URLS.STUDIO) {
      const scraper = new StudioScraper(url);
      const studios = await scraper.scrape();
      allStudios.push(...studios);
    }

    // DynamoDBì— ì¼ê´„ ì €ìž¥
    if (allStudios.length > 0) {
      await batchWrite(allStudios);
      console.log(`Successfully saved ${allStudios.length} studios to database`);
    }

    return {
      statusCode: 200,
      body: JSON.stringify({
        message: 'Studio scraping completed',
        count: allStudios.length
      })
    };
  } catch (error) {
    console.error('Studio scraping failed:', error);
    return {
      statusCode: 500,
      body: JSON.stringify({
        message: 'Studio scraping failed',
        error: error.message
      })
    };
  }
};
