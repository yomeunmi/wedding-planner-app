// ë¡œì»¬ ê°œë°œ í™˜ê²½ ê°ì§€
const isOffline = process.env.IS_OFFLINE || process.env.NODE_ENV === 'development';

/**
 * ë©”ì´í¬ì—… ì •ë³´ ìŠ¤í¬ëž˜í•‘ Lambda í•¸ë“¤ëŸ¬
 */
module.exports.scrape = async (event) => {
  console.log('Makeup scraping handler called');

  // ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ìŠ¤í¬ëž˜í•‘ ìŠ¤í‚µ
  if (isOffline) {
    console.log('ðŸ”§ Running in offline mode - skipping scraping');
    return {
      statusCode: 200,
      body: JSON.stringify({
        message: 'ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” ìŠ¤í¬ëž˜í•‘ì„ ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.',
        isOffline: true,
        note: 'AWSì— ë°°í¬ í›„ ì‹¤ì œ ìŠ¤í¬ëž˜í•‘ì´ ì‹¤í–‰ë©ë‹ˆë‹¤.'
      })
    };
  }

  try {
    const MakeupScraper = require('../scrapers/makeupScraper');
    const { batchWrite } = require('../utils/dynamodb');
    const { SCRAPE_URLS } = require('../config/constants');

    console.log('Starting makeup scraping...');
    const allMakeupShops = [];

    // ëª¨ë“  URLì—ì„œ ìŠ¤í¬ëž˜í•‘
    for (const url of SCRAPE_URLS.MAKEUP) {
      const scraper = new MakeupScraper(url);
      const makeupShops = await scraper.scrape();
      allMakeupShops.push(...makeupShops);
    }

    // DynamoDBì— ì¼ê´„ ì €ìž¥
    if (allMakeupShops.length > 0) {
      await batchWrite(allMakeupShops);
      console.log(`Successfully saved ${allMakeupShops.length} makeup shops to database`);
    }

    return {
      statusCode: 200,
      body: JSON.stringify({
        message: 'Makeup scraping completed',
        count: allMakeupShops.length
      })
    };
  } catch (error) {
    console.error('Makeup scraping failed:', error);
    return {
      statusCode: 500,
      body: JSON.stringify({
        message: 'Makeup scraping failed',
        error: error.message
      })
    };
  }
};
