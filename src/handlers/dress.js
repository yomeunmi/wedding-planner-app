// ë¡œì»¬ ê°œë°œ í™˜ê²½ ê°ì§€
const isOffline = process.env.IS_OFFLINE || process.env.NODE_ENV === 'development';

/**
 * ë“œë ˆìŠ¤ìƒµ ì •ë³´ ìŠ¤í¬ëž˜í•‘ Lambda í•¸ë“¤ëŸ¬
 */
module.exports.scrape = async (event) => {
  console.log('Dress shop scraping handler called');

  // ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ìŠ¤í¬ëž˜í•‘ ìŠ¤í‚µ
  if (isOffline) {
    console.log('ðŸ”§ Running in offline mode - skipping scraping');
    return {
      statusCode: 200,
      body: JSON.stringify({
        message: 'ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” ìŠ¤í¬ëž˜í•‘ì„ ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.',
        isOffline: true,
        note: 'AWSì— ë°°í¬ í›„ ì‹¤ì œ ìŠ¤í¬ëž˜í•‘ì´ ì‹¤í–‰ë©ë‹ˆë‹¤.'
      })
    };
  }

  try {
    const DressScraper = require('../scrapers/dressScraper');
    const { batchWrite } = require('../utils/dynamodb');
    const { SCRAPE_URLS } = require('../config/constants');

    console.log('Starting dress shop scraping...');
    const allDressShops = [];

    // ëª¨ë“  URLì—ì„œ ìŠ¤í¬ëž˜í•‘
    for (const url of SCRAPE_URLS.DRESS) {
      const scraper = new DressScraper(url);
      const dressShops = await scraper.scrape();
      allDressShops.push(...dressShops);
    }

    // DynamoDBì— ì¼ê´„ ì €ìž¥
    if (allDressShops.length > 0) {
      await batchWrite(allDressShops);
      console.log(`Successfully saved ${allDressShops.length} dress shops to database`);
    }

    return {
      statusCode: 200,
      body: JSON.stringify({
        message: 'Dress shop scraping completed',
        count: allDressShops.length
      })
    };
  } catch (error) {
    console.error('Dress shop scraping failed:', error);
    return {
      statusCode: 500,
      body: JSON.stringify({
        message: 'Dress shop scraping failed',
        error: error.message
      })
    };
  }
};
